# ARM W4A8 ì „ìš© Makefile
# ì‚¬ìš©ë²•: make -f Makefile.arm

# ARM ìµœì í™” ì„¤ì •
CC := gcc
CXX := g++
CFLAGS := -O3 -march=armv8-a+dotprod+i8mm -mtune=cortex-a76 -DGGML_USE_LLAMAFILE -DGGML_USE_KLEIDIAI
CXXFLAGS := -O3 -march=armv8-a+dotprod+i8mm -mtune=cortex-a76 -DGGML_USE_LLAMAFILE -DGGML_USE_KLEIDIAI -std=c++17
LDFLAGS := -lm -lpthread

# KleidiAI í™œì„±í™” í”Œë˜ê·¸
CFLAGS += -DGGML_CPU_KLEIDIAI=1
CXXFLAGS += -DGGML_CPU_KLEIDIAI=1

# W4A8 ë””ë²„ê·¸ í™œì„±í™”
CFLAGS += -DDEBUG_W4A8=1
CXXFLAGS += -DDEBUG_W4A8=1

# ì†ŒìŠ¤ íŒŒì¼ë“¤
GGML_SOURCES := \
	ggml/src/ggml.c \
	ggml/src/ggml-cpu/ggml-cpu.c \
	ggml/src/ggml-cpu/ggml-cpu-quants.c \
	ggml/src/ggml-cpu/llamafile/sgemm.cpp \
	ggml/src/ggml-cpu/kleidiai/kleidiai.cpp \
	ggml/src/ggml-cpu/kleidiai/kernels.cpp

LLAMA_SOURCES := \
	src/llama.cpp \
	src/llama-model.cpp \
	src/llama-context.cpp \
	src/llama-model-loader.cpp \
	src/llama-vocab.cpp \
	src/llama-grammar.cpp \
	src/llama-sampling.cpp \
	src/unicode.cpp

COMMON_SOURCES := \
	common/common.cpp \
	common/sampling.cpp \
	common/console.cpp \
	common/grammar-parser.cpp

# ë¹Œë“œ íƒ€ê²Ÿ
all: llama-cli-arm

llama-cli-arm: tools/main/main.cpp $(GGML_SOURCES) $(LLAMA_SOURCES) $(COMMON_SOURCES)
	$(CXX) $(CXXFLAGS) -Iggml/include -Iinclude -Icommon -o $@ $^ $(LDFLAGS)

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
test-w4a8: llama-cli-arm
	@echo "ğŸ§ª Testing W4A8 on ARM..."
	@echo "âš ï¸  Q4_0 ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤!"
	@echo "ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”:"
	@echo "   ./llama-cli-arm -m your_model_Q4_0.gguf -p \"Hello World\" -n 3"

clean:
	rm -f llama-cli-arm

.PHONY: all test-w4a8 clean 