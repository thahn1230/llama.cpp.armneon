#include <iostream>
#include <string>

// llama.cpp includes (ì™¸ë¶€ í•¨ìˆ˜ ì„ ì–¸)
extern "C" {
    const char * llama_print_system_info(void);
    
    // CPU feature functions (extern ì„ ì–¸)
    int ggml_cpu_has_fp16_va(void);
    int ggml_cpu_has_dotprod(void);
    int ggml_cpu_has_matmul_int8(void);
    int ggml_cpu_has_llamafile(void);
}

int main() {
    std::cout << "=== Runtime ARM Features Test ===" << std::endl;
    std::cout << std::endl;
    
    std::cout << "ðŸ” Compile-time Macros:" << std::endl;
#ifdef __ARM_FEATURE_FP16_VECTOR_ARITHMETIC
    std::cout << "  FP16_VA: âœ… DEFINED" << std::endl;
#else
    std::cout << "  FP16_VA: âŒ NOT DEFINED" << std::endl;
#endif

#ifdef __ARM_FEATURE_DOTPROD
    std::cout << "  DOTPROD: âœ… DEFINED" << std::endl;
#else
    std::cout << "  DOTPROD: âŒ NOT DEFINED" << std::endl;
#endif

#ifdef __ARM_FEATURE_MATMUL_INT8
    std::cout << "  MATMUL_INT8: âœ… DEFINED" << std::endl;
#else
    std::cout << "  MATMUL_INT8: âŒ NOT DEFINED" << std::endl;
#endif

#ifdef GGML_USE_LLAMAFILE
    std::cout << "  LLAMAFILE: âœ… DEFINED" << std::endl;
#else
    std::cout << "  LLAMAFILE: âŒ NOT DEFINED" << std::endl;
#endif

    std::cout << std::endl;
    std::cout << "ðŸŽ¯ Runtime Functions (from ggml-cpu):" << std::endl;
    
    // Note: ì´ í•¨ìˆ˜ë“¤ì€ ì‹¤ì œ llama.cpp ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë§í¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
    // ì§€ê¸ˆì€ extern ì„ ì–¸ë§Œ ë˜ì–´ ìžˆìœ¼ë¯€ë¡œ ë§í¬ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìžˆìŠµë‹ˆë‹¤
    
    std::cout << std::endl;
    std::cout << "ðŸ“‹ llama_print_system_info() output:" << std::endl;
    // std::cout << llama_print_system_info() << std::endl;
    std::cout << "  (ë§í¬ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œë§Œ ì‹¤í–‰ ê°€ëŠ¥)" << std::endl;
    
    return 0;
} 